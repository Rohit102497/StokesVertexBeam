{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 303, 303, 3), (15000, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading .h5 file\n",
    "\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "hdf5_dir = Path(\"/StokesVertexBeam/Data/hdf5/\")\n",
    "hdf5_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def read_many_hdf5(num_images):\n",
    "    \"\"\" Reads image from HDF5.\n",
    "        Parameters:\n",
    "        ---------------\n",
    "        num_images   number of images to read\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        images      images array, (N, 32, 32, 3) to be stored\n",
    "        labels      associated meta data, int label (N, 1)\n",
    "    \"\"\"\n",
    "    images, labels = [], []\n",
    "\n",
    "    # Open the HDF5 file\n",
    "    # file = h5py.File(hdf5_dir / f\"{num_images}_many.h5\", \"r+\")\n",
    "    # file = h5py.File(hdf5_dir / f\"experimental_{num_images}_many.h5\", \"r+\")\n",
    "    file = h5py.File(hdf5_dir / f\"{num_images}_From10000each_303_303_many.h5\", \"r+\")    \n",
    "\n",
    "    images = np.array(file[\"/images\"]).astype(\"uint8\")\n",
    "    labels = np.array(file[\"/meta\"]).astype(\"uint8\")\n",
    "\n",
    "    return images, labels\n",
    "    \n",
    "corr_img, labels = read_many_hdf5(15000)\n",
    "\n",
    "corr_img.shape, labels .shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split in 3 parts - Train, Val, Test : 70%, 20%, 10%\n",
    "import random\n",
    "\n",
    "train_sample = random.sample(list(range(0, corr_img.shape[0])), int(corr_img.shape[0]*.7))\n",
    "left_sample = list(set(list(range(0, corr_img.shape[0]))) - set(train_sample))\n",
    "val_sample = random.sample(left_sample, int(corr_img.shape[0]*.2))\n",
    "test_sample = list(set(left_sample) - set(val_sample))\n",
    "\n",
    "train_img, train_label = corr_img[train_sample], labels[train_sample]\n",
    "val_img, val_label = corr_img[val_sample], labels[val_sample]\n",
    "test_img, test_label = corr_img[test_sample], labels[test_sample]\n",
    "\n",
    "# experimental_img, experimental_label = corr_img, labels\n",
    "\n",
    "del corr_img, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(corr_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_dir = [\"Class1_phi12_01/\", \"Class2_phi12_02/\", \"Class3_phi12_10/\",\n",
    "#             \"Class4_phi12_12/\", \"Class5_phi12_23/\", \"Class6_phi23_01/\",\n",
    "#             \"Class7_phi23_02/\", \"Class8_phi23_10/\", \"Class9_phi23_12/\",\n",
    "#             \"Class10_phi23_23/\", \"Class11_phi31_01/\", \"Class12_phi31_02/\",\n",
    "#             \"Class13_phi31_10/\", \"Class14_phi31_12/\", \"Class15_phi31_23/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/StokesVertexBeam/Data/DesignData/Design1_1000From10000/train/\"\n",
    "\n",
    "from PIL import Image\n",
    "for i in range(train_img.shape[0]):\n",
    "    im = Image.fromarray(train_img[i])\n",
    "    image_path = train_path + \"Class\" + str(train_label[i][0]) + \"/\" + str(i) + \".jpg\"\n",
    "    im.save(image_path)\n",
    "\n",
    "val_path = \"/StokesVertexBeam/Data/DesignData/Design1_1000From10000/val/\"\n",
    "\n",
    "from PIL import Image\n",
    "for i in range(val_img.shape[0]):\n",
    "    im = Image.fromarray(val_img[i])\n",
    "    image_path = val_path + \"Class\" + str(val_label[i][0]) + \"/\" + str(i) + \".jpg\"\n",
    "    im.save(image_path)\n",
    "\n",
    "test_path = \"/StokesVertexBeam/Data/DesignData/Design1_1000From10000/test/\"\n",
    "\n",
    "from PIL import Image\n",
    "for i in range(test_img.shape[0]):\n",
    "    im = Image.fromarray(test_img[i])\n",
    "    image_path = test_path + \"Class\" + str(test_label[i][0]) + \"/\" + str(i) + \".jpg\"\n",
    "    im.save(image_path)\n",
    "\n",
    "# experimental_path = \"/StokesVertexBeam/Data/NewCodeData/experimental/\"\n",
    "\n",
    "# from PIL import Image\n",
    "# for i in range(experimental_img.shape[0]):\n",
    "#     im = Image.fromarray(experimental_img[i])\n",
    "#     image_path = experimental_path + \"Class\" + str(experimental_label[i][0]) + \"/\" + str(i) + \".jpg\"\n",
    "#     im.save(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# store_many_hdf5(corr_img, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "212fe4dcc2058c2b360a90727b41e33f0c7d5ebe4a945874be24d9abef50c1d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
