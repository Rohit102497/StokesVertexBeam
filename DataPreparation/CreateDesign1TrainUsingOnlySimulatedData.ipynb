{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 101, 707, 3), (300, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading .h5 file\n",
    "\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "hdf5_dir = Path(\"/Users/rag004/Documents/PhD/Code/VertexBeam/Data/hdf5/\")\n",
    "hdf5_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def read_many_hdf5(num_images):\n",
    "    \"\"\" Reads image from HDF5.\n",
    "        Parameters:\n",
    "        ---------------\n",
    "        num_images   number of images to read\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        images      images array, (N, 32, 32, 3) to be stored\n",
    "        labels      associated meta data, int label (N, 1)\n",
    "    \"\"\"\n",
    "    images, labels = [], []\n",
    "\n",
    "    # Open the HDF5 file\n",
    "    # file = h5py.File(hdf5_dir / f\"{num_images}_many.h5\", \"r+\")\n",
    "    file = h5py.File(hdf5_dir / f\"experimental_{num_images}_many.h5\", \"r+\")    \n",
    "\n",
    "    images = np.array(file[\"/images\"]).astype(\"uint8\")\n",
    "    labels = np.array(file[\"/meta\"]).astype(\"uint8\")\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "def store_many_hdf5(images, labels):\n",
    "    \"\"\" Stores an array of images to HDF5.\n",
    "        Parameters:\n",
    "        ---------------\n",
    "        images       images array, (N, 32, 32, 3) to be stored\n",
    "        labels       labels array, (N, 1) to be stored\n",
    "    \"\"\"\n",
    "    num_images = len(images)\n",
    "\n",
    "    # Create a new HDF5 file\n",
    "    file = h5py.File(hdf5_dir / f\"{num_images}_303_303many.h5\", \"w\")\n",
    "\n",
    "    # Create a dataset in the file\n",
    "    dataset = file.create_dataset(\n",
    "        \"images\", np.shape(images), h5py.h5t.STD_U8BE, data=images\n",
    "    )\n",
    "    meta_set = file.create_dataset(\n",
    "        \"meta\", np.shape(labels), h5py.h5t.STD_U8BE, data=labels\n",
    "    )\n",
    "    file.close()\n",
    "    \n",
    "images, labels = read_many_hdf5(300)\n",
    "\n",
    "images.shape, labels .shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 303, 303, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Preparation\n",
    "ze = np.zeros((images.shape[0], 101, 202, 3))\n",
    "new_img = np.concatenate((images, ze), axis = 2)\n",
    "# new_img = np.concatenate((images, ze), axis = 2)/255\n",
    "\n",
    "del ze, images\n",
    "\n",
    "a = new_img[:, :, :303, :]\n",
    "b = new_img[:, :, 303:606, :]\n",
    "c = new_img[:, :, 606:909, :]\n",
    "\n",
    "del new_img\n",
    "\n",
    "corr_img = np.concatenate((a,b,c), axis = 1).astype(np.uint8)\n",
    "\n",
    "del a, b, c\n",
    "\n",
    "corr_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data split in 3 parts - Train, Val, Test : 70%, 20%, 10%\n",
    "# import random\n",
    "\n",
    "# train_sample = random.sample(list(range(0, corr_img.shape[0])), int(corr_img.shape[0]*.7))\n",
    "# left_sample = list(set(list(range(0, corr_img.shape[0]))) - set(train_sample))\n",
    "# val_sample = random.sample(left_sample, int(corr_img.shape[0]*.2))\n",
    "# test_sample = list(set(left_sample) - set(val_sample))\n",
    "\n",
    "# train_img, train_label = corr_img[train_sample], labels[train_sample]\n",
    "# val_img, val_label = corr_img[val_sample], labels[val_sample]\n",
    "# test_img, test_label = corr_img[test_sample], labels[test_sample]\n",
    "\n",
    "experimental_img, experimental_label = corr_img, labels\n",
    "\n",
    "del corr_img, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(corr_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_dir = [\"Class1_phi12_01/\", \"Class2_phi12_02/\", \"Class3_phi12_10/\",\n",
    "#             \"Class4_phi12_12/\", \"Class5_phi12_23/\", \"Class6_phi23_01/\",\n",
    "#             \"Class7_phi23_02/\", \"Class8_phi23_10/\", \"Class9_phi23_12/\",\n",
    "#             \"Class10_phi23_23/\", \"Class11_phi31_01/\", \"Class12_phi31_02/\",\n",
    "#             \"Class13_phi31_10/\", \"Class14_phi31_12/\", \"Class15_phi31_23/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path = \"/Users/rag004/Documents/PhD/Code/VertexBeam/Data/NewCodeData/train/\"\n",
    "\n",
    "# from PIL import Image\n",
    "# for i in range(train_img.shape[0]):\n",
    "#     im = Image.fromarray(train_img[i])\n",
    "#     image_path = train_path + \"Class\" + str(train_label[i][0]) + \"/\" + str(i) + \".jpg\"\n",
    "#     im.save(image_path)\n",
    "\n",
    "# val_path = \"/Users/rag004/Documents/PhD/Code/VertexBeam/Data/NewCodeData/val/\"\n",
    "\n",
    "# from PIL import Image\n",
    "# for i in range(val_img.shape[0]):\n",
    "#     im = Image.fromarray(val_img[i])\n",
    "#     image_path = val_path + \"Class\" + str(val_label[i][0]) + \"/\" + str(i) + \".jpg\"\n",
    "#     im.save(image_path)\n",
    "\n",
    "# test_path = \"/Users/rag004/Documents/PhD/Code/VertexBeam/Data/NewCodeData/test/\"\n",
    "\n",
    "# from PIL import Image\n",
    "# for i in range(test_img.shape[0]):\n",
    "#     im = Image.fromarray(test_img[i])\n",
    "#     image_path = test_path + \"Class\" + str(test_label[i][0]) + \"/\" + str(i) + \".jpg\"\n",
    "#     im.save(image_path)\n",
    "\n",
    "experimental_path = \"/Users/rag004/Documents/PhD/Code/VertexBeam/Data/NewCodeData/experimental/\"\n",
    "\n",
    "from PIL import Image\n",
    "for i in range(experimental_img.shape[0]):\n",
    "    im = Image.fromarray(experimental_img[i])\n",
    "    image_path = experimental_path + \"Class\" + str(experimental_label[i][0]) + \"/\" + str(i) + \".jpg\"\n",
    "    im.save(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# store_many_hdf5(corr_img, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
